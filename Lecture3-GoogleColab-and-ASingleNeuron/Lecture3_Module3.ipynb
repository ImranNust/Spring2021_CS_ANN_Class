{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Single Neuron\n",
    "\n",
    "In this module, we will learn:\n",
    "1. How does a single neuron work?\n",
    "2. Forward Propagation\n",
    "3. Backward Propagation\n",
    "4. Optimization Algorithm\n",
    "5. Loss Function\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## How does a single neuron work?\n",
    "\n",
    "The working of a neuron involves following steps:\n",
    "1. Defining input and output\n",
    "2. Forward Propagation\n",
    "3. Computing Loss\n",
    "4. Backward Propagation\n",
    "5. Updating weights and biases\n",
    "\n",
    "We continue from step 2 through step 5 untill we get either zero or very small loss value.\n",
    "\n",
    "We, in this module, discuss each step in a bit detail.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Defining Inputs and Outputs\n",
    "\n",
    "We have the following pattern between input(feature) and output(target)\n",
    "\n",
    "| Example  Numbers      | Features (x) | Target (y)    |\n",
    "| :---                  |    :----:    |          ---: |\n",
    "| 1                     | 1            | 2             |\n",
    "| 2                     | 2            | 4             |\n",
    "| 3                     | 3            | 6             |\n",
    "| 4                     | 4            | 8             |\n",
    "| 5                     | 5            | 10            |\n",
    "| 6                     | 6            | 12            |\n",
    "| $\\vdots$              | $\\vdots$     | $\\vdots$      |\n",
    "| $\\vdots$              | $\\vdots$     | $\\vdots$      |\n",
    "| 100                   | 100          | 200           |\n",
    "\n",
    "The task of the neuron is to find the $w$ and $b$ for the following equation, which shows a relationship between input(x) and output(y).\n",
    "\\begin{equation}\n",
    "y = wx + b\n",
    "\\end{equation}\n",
    "\n",
    "In the above equation, $w$ and $b$, are called weight and bias, respectively.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Forward Propagation\n",
    "\n",
    "![Pic1Module2](Pic1Module2.png)\n",
    "\n",
    "The forward propagation involves the following steps.\n",
    "1. Initializing weights and biases. **Please note that initializing weights and biases is done at the begining of training but not with every epoch.**\n",
    "2. Compute $Z = W * X + b $\n",
    "3. Passing the value of $Z$ through an activation function to get $\\hat{Y}$; that is, \n",
    "$$Y = f(Z).$$ \n",
    "In this module, we are using a linear activation function; therefore, $\\hat{Y} = Z.$\n",
    "\n",
    "\n",
    "Please note that we will learn about activation functions in detail in next lectures.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Initializing weights and biases\n",
    "\n",
    "Since there is only one layer and one neuron; therefore, we have to initialize only one weight value and one bias value. Let's say that we initialized the weight and bias to be $$w = 1.2,$$ and $$b = 0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Computing $z = wx + b$\n",
    "\n",
    "\\begin{equation}\n",
    "z = 1.2 * 1 + 0 = 1.2\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Computing $\\hat{y} = z$\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = z = 1.2\n",
    "\\end{equation}\n",
    "\n",
    "We can see that the computed output $\\hat{y} = 1.2$; whereas, the actual output was $y = 2$. So, the next step is to calculate the loss to determine how far the estimated output is from the actual output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Loss Function\n",
    "We will compute the loss to determine the disparity between the estimated and the actual output values. There are many loss functions, which will discuss in detail later; however, here, we are using **Mean Squared Error** loss function.\n",
    "\n",
    "The MSE loss function is defined as:\n",
    "\\begin{eqnarray}\n",
    "\\mathcal{L\\left(y, \\hat{y}\\right)} = \\frac{1}{N}\\sum_{i=1}{N}\\left(y-\\hat{y}\\right)^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "Since, in the given module, we are using stochastic gradient descent; we will feed single example to the model and update parameters (w and b) for each example; therefore, the MSE formula will be reduced to $(2)$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L\\left(y, \\hat{y}\\right)} = \\left(y-\\hat{y}\\right)^2\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compute the loss\n",
    "We will compute the loss for given example as follows:\n",
    "\\begin{eqnarray}\n",
    "\\mathcal{L\\left(y, \\hat{y}\\right)} = & \\left(2-1.2\\right)^2 \\\\\n",
    "= & 0.64\n",
    "\\end{eqnarray}\n",
    "\n",
    "The loss is too much; that is, $0.64$, which is an indication that our model is not performing well. Therefore, in the next step, we will update $w$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the parameters\n",
    "\n",
    "When a neural network model does not perform well, the weights and biases are updated using any optimization algoritm. The weights are updated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "w : = w - \\alpha dw \\\\\n",
    "b : = b - \\alpha db\n",
    "\\end{equation}\n",
    "In the above equation, $\\alpha$ is the learning parameter, and, in the given example, we have opted it be $0.09$. Furthermore, for a stochastic gradient descent optimization, $dw$ and $db$ are as follows:\n",
    "\\begin{equation}\n",
    "dw  = -2(y-\\hat{y})x\\\\\n",
    "db = -2(y-\\hat{y})\n",
    "\\end{equation}\n",
    "\n",
    "**Please note that $dw$ and $db$ are different for different optimization algorithms and activation functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Updating the weight and bias\n",
    "We will update the weight and bias according to the above-mentioned equations.\n",
    "\n",
    "First, we will calculate dw and db.\n",
    "\n",
    "\\begin{equation}\n",
    "dw  = -2(y-\\hat{y})x = -2*(2 - 1.2)*1 = -1.6\\\\\n",
    "db = -2(y-\\hat{y}) = -2*(2-1.2) = -1.6\n",
    "\\end{equation}\n",
    "\n",
    "Second, we will update w and b as follows:\n",
    "\\begin{equation}\n",
    "w : = w - \\alpha dw = 1.2 - 0.09*(-1.6) = 1.34\\\\\n",
    "b : = b - \\alpha db = 0 - 0.09*(-1.6) = 0.144\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that if we use the updated values of $w$ and $b$ to compute the output $\\hat{y}$ for $x=1$, we will get a better approximation. However, we will proceed with second example; that is, $x = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "\n",
    "Now we will repeat from step 2 through step 5 for all 100 examples, and all this will make a single epoch. We will train the model for a number of epochs untill the loss becomes neglible."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Module4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
