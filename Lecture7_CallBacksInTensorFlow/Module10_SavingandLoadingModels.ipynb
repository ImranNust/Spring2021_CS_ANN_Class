{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Module10_SavingandLoadingModels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhHJcvK8QV4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e14264c-e2f0-4a99-8363-1a537e6903b8"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8KAKynxQV4e"
      },
      "source": [
        "# Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8AXiHR6lWjq"
      },
      "source": [
        "***\n",
        "It's possible to manually save the weights of a model, for example, after a training run has completed. \n",
        "\n",
        "There are two different formats available for saving and loading files: a native TensorFlow format as well as the HDF5 format used by Keras. \n",
        "\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEkcogTMlbBz"
      },
      "source": [
        "\n",
        "## Preparing Dataset \n",
        "\n",
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdhCQF7BwWKb",
        "outputId": "3db1f0cc-8a72-47f5-ce71-35b134c6d624"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcevGi3cwcul"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1e7al0IwfKH",
        "outputId": "d60ada03-7a95-4c8b-d3dc-bea0b46469b0"
      },
      "source": [
        "# Define a simple sequential model\n",
        "def create_model():\n",
        "  model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(784,)),\n",
        "    Dropout(0.2),\n",
        "    Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Display the model's architecture\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pLLH45iwh0r"
      },
      "source": [
        "## Saving only Weights using the Modelcheckpoint Callback\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPVBiMwIwo5l",
        "outputId": "a1e61166-77ca-4a3a-deaf-71d68d78b84f"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_dir = '/content/modelcheckpoints'\n",
        "\n",
        "# deleting any directory if there is any\n",
        "!rm -r modelcheckpoints\n",
        "\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath = checkpoint_dir,\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 2,\n",
        "    save_best_only = False,\n",
        "    save_weights_only = True,\n",
        "    mode = 'auto',\n",
        "    save_freq = 'epoch'\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'modelcheckpoints': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QSt0XhAxFp4"
      },
      "source": [
        "Now use the above instance `cp_callback` int the `model.fit` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z63D0YixD2Y",
        "outputId": "f7d9446a-f57f-491f-df05-e1731d495eb8"
      },
      "source": [
        "history = model.fit(\n",
        "    x = train_images, y = train_labels,\n",
        "    batch_size = 64, epochs = 5, verbose = 0, callbacks = [cp_callback],\n",
        "    validation_data = (test_images, test_labels)\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: saving model to /content/modelcheckpoints\n",
            "\n",
            "Epoch 00002: saving model to /content/modelcheckpoints\n",
            "\n",
            "Epoch 00003: saving model to /content/modelcheckpoints\n",
            "\n",
            "Epoch 00004: saving model to /content/modelcheckpoints\n",
            "\n",
            "Epoch 00005: saving model to /content/modelcheckpoints\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx7PPsrAxrJK"
      },
      "source": [
        "Let's check original model's loss and with loaded wieghts loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urg4dc-3x1nM",
        "outputId": "103fb21c-98f8-42a1-894f-6a27348839b6"
      },
      "source": [
        "loss, acc = model.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Original Model is {:.4f}.'.format(loss))\n",
        "\n",
        "# Build a new model\n",
        "model_1 = create_model()\n",
        "model_1.load_weights(filepath=checkpoint_dir)\n",
        "loss, acc = model_1.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Loaded Weights is {:.4f}.'.format(loss))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss with Original Model is 0.4444.\n",
            "Test Loss with Loaded Weights is 0.4444.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGJTme8uzj8i"
      },
      "source": [
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQuIXU5slfrP"
      },
      "source": [
        "## Saving and loading models in h5 Formate\n",
        "\n",
        "There's also an alternative formats that we can use to save the model weights. The formats used by Keras is the HDF5 format. These file formats often use the extension .h5. \n",
        "\n",
        "If we give the file path argument, the h5 extension, as shown below, then the model will save the weights in the Keras HDF5 format. \n",
        "\n",
        "```\n",
        "checkpoint = ModelCheckpoint('my_model.h5', save_weights_only = True)\n",
        "```\n",
        "\n",
        "After running the training, we will see that the model weights will have saved to a single HDF5 file in the current working directory. \n",
        "```\n",
        "my_model.h5\n",
        "```\n",
        "\n",
        "**For most models, it doesn't really make a difference which format we use but in general, using the native TensorFlow format is recommended.** \n",
        "\n",
        "***\n",
        "\n",
        "We can save the model weights manually; that is, without using the `ModelCheckpoint` callback, using\n",
        "\n",
        "```\n",
        "model.save_weights('my_model')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joyEmiDk0a5b"
      },
      "source": [
        "del model, model_1\n",
        "# Let's create a new model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model just for 5 epochs\n",
        "history = model.fit(\n",
        "    x = train_images, y = train_labels,\n",
        "    batch_size = 64, epochs = 5, verbose = 0,\n",
        "    validation_data = (test_images, test_labels)\n",
        ")\n",
        "\n",
        "# Save the weights\n",
        "model.save_weights(filepath = 'my_model.h5',\n",
        "                   save_format = 'h5')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MAts9q0lkef"
      },
      "source": [
        "Let's check original model's loss and with loaded wieghts loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727lSD0p2YH7",
        "outputId": "74f8f889-dc48-4772-acd7-cd0c62048895"
      },
      "source": [
        "loss, acc = model.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Original Model is {:.4f}.'.format(loss))\n",
        "\n",
        "# Build a new model\n",
        "model_1 = create_model()\n",
        "model_1.load_weights('my_model.h5')\n",
        "loss, acc = model_1.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Loaded Weights is {:.4f}.'.format(loss))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss with Original Model is 0.4523.\n",
            "Test Loss with Loaded Weights is 0.4523.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lURwi3yfQf8_"
      },
      "source": [
        "***\n",
        "## Saving the entire model\n",
        "\n",
        "\n",
        "If we want the entire model to be saved not just weights, then we will set the parameter `save_weights_only` to be `False`. In fact, this is the default value for this keyword argument, so we could have just left it out altogether. \n",
        "\n",
        "***\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeiRO7rbSgUR"
      },
      "source": [
        "Whenever we save the entire model, files like the one shown below, are created.\n",
        "1. my_model/assets/\n",
        "2. my_model/saved_model.pb\n",
        "3. my_model/variables/variables.data-000000-of-00001\n",
        "4. my_model/variables/variables.index\n",
        "\n",
        "Remember before, the callback used the file path `my_model` in the name of the files that were saved in the current working directory. Now, because we're saving the entire model and not just the weights, the file path `my_model` is used to create a subdirectory within the current working directory.\n",
        "\n",
        "Inside that, you'll find two more subdirectories, `assets` and `variables`. The `assets` folder is where files can be stored that are used by the TensorFlow graph. In our simple example, this folder would be empty.\n",
        "\n",
        "The `variables` folder contains the saved weights of the model. These file names should look familiar from when we were saving weights only.\n",
        "\n",
        "The last file here, `saved_model.pb`, is the file that stores the TensorFlow graph itself. You can think of this as storing the model architecture. So it contains all the information from when we built and compiled the model, including the optimizer state, in case we want to resume training from a saved model.\n",
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_PgceYs3jdL",
        "outputId": "810bb9b7-0f04-41af-f653-0db1a68ecb10"
      },
      "source": [
        "del model\n",
        "!rm -r save_model\n",
        "# Creating a new model\n",
        "model = create_model()\n",
        "\n",
        "# Instantiating the callback to save the model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "save_model_dir = '/content/save_model/'\n",
        "save_model_callback = ModelCheckpoint(\n",
        "    filepath = save_model_dir,\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 2,\n",
        "    save_weights_only = False\n",
        ")\n",
        "\n",
        "# Traing using the callback\n",
        "history = model.fit(x = train_images, y = train_labels,\n",
        "                    batch_size = 64, epochs = 5, verbose = False,\n",
        "                    validation_data = (test_images, test_labels),\n",
        "                    callbacks = [save_model_callback])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'save_model': No such file or directory\n",
            "\n",
            "Epoch 00001: saving model to /content/save_model/\n",
            "INFO:tensorflow:Assets written to: /content/save_model/assets\n",
            "\n",
            "Epoch 00002: saving model to /content/save_model/\n",
            "INFO:tensorflow:Assets written to: /content/save_model/assets\n",
            "\n",
            "Epoch 00003: saving model to /content/save_model/\n",
            "INFO:tensorflow:Assets written to: /content/save_model/assets\n",
            "\n",
            "Epoch 00004: saving model to /content/save_model/\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "INFO:tensorflow:Assets written to: /content/save_model/assets\n",
            "\n",
            "Epoch 00005: saving model to /content/save_model/\n",
            "INFO:tensorflow:Assets written to: /content/save_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6sUzaSn66_B",
        "outputId": "9906354b-f9eb-41a6-b84c-19fdc82a4d5e"
      },
      "source": [
        "loss, acc = model.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Original Model is {:.4f}.'.format(loss))\n",
        "\n",
        "# Build a new model\n",
        "model_1 = tf.keras.models.load_model(save_model_dir)\n",
        "\n",
        "loss, acc = model_1.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Loaded Weights is {:.4f}.'.format(loss))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss with Original Model is 0.4392.\n",
            "Test Loss with Loaded Weights is 0.4392.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kL20HrwTWXX"
      },
      "source": [
        "***\n",
        "## Saving the entire model in h5 formate\n",
        "\n",
        "we can also save the entire model in the Keras HDF5 format. In this case, just one file will be saved, which is the **keras_model.h5** file.\n",
        "```\n",
        "checkpoint = ModelCheckpoint('my_model.h5', save_weights_only=False) \n",
        "model.fit(x_train, y_train, epochs=10, callbacks = [checkpoint])\n",
        "```\n",
        "\n",
        "This looks the same as when we saved weights only, but this HDF5 file now contains the architecture as well as the weights.\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKJWEXWvuiv6"
      },
      "source": [
        "We can also manually save the entire model, just as we manually saved the weights of a model after a training run. If you remember, when we saved the weights, we used `model.save_weights`. The only difference here is that we're using `model.save`. This method will now save the entire model, architecture and weights, in the same directory structure as before for the native TensorFlow saved model format.\n",
        "```\n",
        "model.save('my_model') # SaveModel Format\n",
        "```\n",
        "***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM6SLmZS8FAl",
        "outputId": "200ef1dd-6556-4002-bcba-db179675f77d"
      },
      "source": [
        "# Creating a new model\n",
        "model2 = create_model()\n",
        "\n",
        "# Instantiating the callback to save the model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "save_model_dir = '/content/save_model.h5'\n",
        "save_model_callback = ModelCheckpoint(\n",
        "    filepath = save_model_dir,\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 2,\n",
        "    save_weights_only = False\n",
        ")\n",
        "\n",
        "# Traing using the callback\n",
        "history = model2.fit(x = train_images, y = train_labels,\n",
        "                    batch_size = 64, epochs = 5, verbose = False,\n",
        "                    validation_data = (test_images, test_labels),\n",
        "                    callbacks = [save_model_callback])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: saving model to /content/save_model.h5\n",
            "\n",
            "Epoch 00002: saving model to /content/save_model.h5\n",
            "\n",
            "Epoch 00003: saving model to /content/save_model.h5\n",
            "\n",
            "Epoch 00004: saving model to /content/save_model.h5\n",
            "\n",
            "Epoch 00005: saving model to /content/save_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z0l537r8mxv",
        "outputId": "b001a02a-8d2e-41a1-deed-de22c6ec3e54"
      },
      "source": [
        "loss, acc = model2.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Original Model is {:.4f}.'.format(loss))\n",
        "\n",
        "# Build a new model\n",
        "model_2 = tf.keras.models.load_model(save_model_dir)\n",
        "\n",
        "loss, acc = model_2.evaluate(test_images, test_labels, verbose = 0)\n",
        "print('Test Loss with Loaded Weights is {:.4f}.'.format(loss))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss with Original Model is 0.4432.\n",
            "Test Loss with Loaded Weights is 0.4432.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2dNGwLzQV55"
      },
      "source": [
        "***\n",
        "***\n",
        "<a id=\"part2b\"></a>\n",
        "## Saving the entire model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0pP6oW1QV57"
      },
      "source": [
        "#### Create checkpoint that saves whole model, not just weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3ROR9KfQV58"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvacO7lDQV5-"
      },
      "source": [
        "# Create Tensorflow checkpoint object\n",
        "\n",
        "checkpoint_path = 'model_checkpoints'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=False, \n",
        "                             save_freq='epoch', \n",
        "                             verbose=1)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ca32hu5QV6l"
      },
      "source": [
        "#### Clear directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftRw7KksQV6m"
      },
      "source": [
        "! rm checkpoint\n",
        "! rm -r save_model\n",
        "! rm my_model.h5\n",
        "!rm save_model.h5"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}