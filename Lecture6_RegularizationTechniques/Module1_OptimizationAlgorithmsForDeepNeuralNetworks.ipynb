{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Module1_OptimizationAlgorithmsForDeepNeuralNetworks.ipynb","provenance":[{"file_id":"1-FvUj5f6x00GJncw238nLzAF2Cckq9Hn","timestamp":1626162014105}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP1Ez19lH9vwQbinnhKNm7M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3rtxEC-Rwrvv"},"source":["# Optimization Algorithms for Deep Neural Networks\n","\n","In this module, we will study:\n","1. Gradient Descent\n","2. Momentum-Based Gradient Descent\n","3. Nesterov Mementum\n","4. Adagrad\n","5. RMSProp\n","6. Adam\n"]},{"cell_type":"markdown","metadata":{"id":"zaGbgMHt16DS"},"source":["## Optimization Algorithms\n","\n","**What is optimization?**\n","\n","In the simplest case, an optimization problem consists of maximizing or minimizing a real function by systematically choosing input values from within an allowed set and computing the value of the function.\n","\n","In the case of Machine Learning or Deep Learning, optimization refers to _the process of minimizing the loss function by systematically updating the network weights_. \n","\n","Mathematically, this is expressed as follows:\n","\n","\\begin{equation}\n","w = argmin_wL(w),\n","\\end{equation}\n","\n","where $L(w)$ and $w$ denotes, respectively, the loss function and weights.\n","\n","***\n","\n","**The Task of an Optimization Algorithm:**\n","\n","Optimization algorithms (in the case of minimization) have one of the following goals:\n","1. Find the global minimum of the objective function. This is feasible if the objective function is convex, i.e. any local minimum is a global minimum.\n","2. Find the lowest possible value of the objective function within its neighborhood. That’s usually the case if the objective function is not convex as the case in most deep learning problems.\n","\n","There are several optimization techniques, we will, in this module, learn the important once.\n","\n","***"]},{"cell_type":"markdown","metadata":{"id":"TURMOyXt3SbC"},"source":["## Gradient Descent\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"POkIk3E07TWE"},"source":["#### What is Gradient Descent?\n","\n","Gradient Descent is an optimizing algorithm used in Machine/ Deep Learning algorithms. It is a first-order (i.e., gradient-based) optimization algorithm where we iteratively update the parameters of a differentiable cost function until its minimum is attained.\n","\n","Mathematically, gardient descent can be defined as follows:\n","\n","\\begin{equation}\n","w := w - \\eta . \\frac{\\partial}{\\partial w} L(w)\n","\\end{equation}\n","\n","In the above equation, $\\eta$ denotes the learning rate.\n","\n","***\n","\n","Visually, the process of gradient descent optimization can be shown as in the following figure.\n","\n","![GradientDescent](gradient-descent.png)\n","\n","***"]},{"cell_type":"markdown","metadata":{"id":"XRpe7gO27QlE"},"source":["#### Steps to Implement Gradient Descent\n","\n","1. Randomly initialize values for weights.\n","2. Update weights using the following formula.\n","\\begin{equation}\n","w := w - \\eta . \\frac{\\partial}{\\partial w} L(w)\n","\\end{equation}\n","\n","3. Repeat until slope = 0; that is, $\\frac{\\partial}{\\partial w} L(w) = 0$."]},{"cell_type":"markdown","metadata":{"id":"yhO-T2Fc6nAu"},"source":["***\n","#### Selection of Learning Rate \n","\n","Learning rate must be chosen wisely as:\n","\n","1. if it is too small, then the model will take some time to learn.\n","2. if it is too large, model will converge as our pointer will shoot and we’ll not be able to get to minima as shown in the following figure.\n","\n","![LearningRate](image1.png)\n","\n","\n","***\n","![LearningRateSelection](image2.png)\n","\n","****\n"]},{"cell_type":"markdown","metadata":{"id":"q56Oatbc7Ve7"},"source":["There are three variants of gradient descent: 1. Batch gradient descent, 2: stochastic gradient descent, and 3. mini-batch gradient descent.\n","\n","## Batch Gradient Descent\n","\n","In this variant, we calculate the gradient for the entire dataset on each training step before we update the weights.\n","\n","\\begin{equation}\n","\\frac{\\partial}{\\partial w} L(w) = \\frac{1}{N} \\sum_{i=1}^{N}\\frac{\\partial}{\\partial w} L_i(x_i, y_i, w)\n","\\end{equation}\n","\n","You can imagine that since we take the sum of the loss of all individual training examples, our computation becomes quickly very expensive. Therefore it’s impractical for large datasets."]},{"cell_type":"markdown","metadata":{"id":"QUamshiN8gWH"},"source":["## Stochastic gradient descent\n","\n","Stochastic Gradient Descent (SGD) was introduced to address this exact issue. Instead of calculating the gradient over all training examples and update the weights, SGD updates the weights for each training example $x_i,y_i$ \n","\n","\n","\n","\\begin{equation}\n","w := w - \\eta \\frac{\\partial}{\\partial w} L_i(x_i, y_i, w)\n","\\end{equation}\n","\n","As a result, SGD is much faster and more computationally efficient, but it has noise in the estimation of the gradient. Since it updates the weight frequently, it can lead to big oscillations, which makes the training process highly unstable."]},{"cell_type":"markdown","metadata":{"id":"QFr8CUWu9E3d"},"source":["## Mini-batch Stochastic Gradient Descent\n","Mini batch SGD sits right in the middle of the two previous ideas combining the best of both worlds. It randomly selects $n$ training examples, the so-called mini-batch, from the whole dataset and computes the gradients only from them. It essentially tries to approximate Batch Gradient Descent by sampling only a subset of the data. Mathematically:\n","\n","\\begin{equation}\n","w := w - \\eta \\frac{\\partial}{\\partial w} L_i(x_{(i:i+n)}, y_{(i:i+n)}, w)\n","\\end{equation}\n","\n","In practice, mini-batch SGD is the most frequently used variation because it’s both computationally cheap and results in more robust convergence."]},{"cell_type":"markdown","metadata":{"id":"btoA2tiQ9g_F"},"source":["***\n","## Concerns on SGD\n","\n","SGD is easy to implement, but it has some limitations:\n","\n","1. If the loss function changes quickly in one direction and slowly in another, it may result in a high oscillation of gradients making the training progress very slow.\n","\n","2. If the loss function has a local minimum or a saddle point, it is very possible that SGD will be stuck there without being able to “jump out” and proceed in finding a better minimum. This happens because the gradient becomes zero so there is no update in the weight whatsoever.\n","\n"," **A saddle point is a point on the surface of the graph of a function where the slopes (derivatives) are all zero but which is not a local maximum of the function.**\n","\n","3. The gradients are still noisy because we estimate them based only on a small sample of our dataset. The noisy updates might not correlate well with the true direction of the loss function.\n","\n","4. Choosing a good loss function is tricky and requires time-consuming experimentation with different hyperparameters.\n","\n","5. The same learning rate is applied to all of our parameters, which can become problematic for features with different frequencies or significance.\n","\n","To overcome some of these problems, many improvements have been proposed over the years.\n"]},{"cell_type":"markdown","metadata":{"id":"j0HRfGco-SO1"},"source":["***\n","## [Momentum-Based SGD](https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d) \n","\n","The overcome the limitation of SGD, a variation, called SGD with momentum, is proposed. For the best explanation, please click on the title of the cell.\n","\n","Mathematically, the SGD with momentum can be defined as:\n","\n","\\begin{equation}\n","V_t = \\beta V_{t-1} + (1-\\beta) \\frac{\\partial}{\\partial w}L(x, y, w) \\\\\n","W := W - \\eta V_t\n","\\end{equation}\n","\n","where\n","- $L$ is the loss function\n","- $\\eta$ is the learning rate\n","- $\\beta$ is the constant, called momentum, and its ideal value is $0.9$.\n","- $V_t$ is a term, called velocity.\n","\n","***"]},{"cell_type":"markdown","metadata":{"id":"p7jQvvInkMxT"},"source":["#### Advantages of Using SGD with Momentum\n","\n","1. We can now escape local minimums or saddle points because we keep moving downwards even though the gradient of the mini-batch might be zero\n","\n","2. Momentum can also help us reduce the oscillation of the gradients because the velocity vectors can smooth out these highly changing landscapes.\n","\n","3. Finally, it reduces the noise of the gradients (stochasticity) and follows a more direct walk down the landscape.\n","\n","***"]},{"cell_type":"markdown","metadata":{"id":"FLEAl2dCkgUi"},"source":["## Nestrov Accelarated Gradient\n","\n","An alternative version of momentum, called Nesterov momentum, calculates the update direction in a slightly different way.\n","\n","Instead of combining the velocity vector and the gradients, we calculate where the velocity vector would take us and compute the gradient at this point. In other words, we find what the gradient vector would have been if we moved only according to our build-up velocity, and compute it from there.\n","\n","We can visualize this as below:\n","\n","![NAG](image3.png)\n","\n","This anticipatory update prevents us from going too fast and results in increased responsiveness. The most famous algorithm that make us of Nesterov momentum is called Nesterov accelerated gradient (NAG) and goes as follows:\n","\n","\\begin{equation}\n","V_t = \\beta V_{t-1} + (1-\\beta) \\frac{\\partial}{\\partial w}L(X, y, w+\\beta V_{t-1}) \\\\\n","W := W - \\eta V_t\n","\\end{equation}\n","\n","where\n","- $L$ is the loss function\n","- $\\eta$ is the learning rate\n","- $\\beta$ is the constant, called momentum, and its ideal value is $0.9$.\n","- $V_t$ is a term, called velocity."]},{"cell_type":"markdown","metadata":{"id":"qf_2FXDal3DE"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"LwW3C2TH0p9h"},"source":["## References\n","\n","1. [A journey into Optimization algorithms for Deep Neural Networks](https://theaisummer.com/optimization/)\n","2. [The Hitchhiker’s Guide to Optimization in Machine Learning](https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-machine-learning-edcf5a104210)\n","3. [Gradient Descent Explained](https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c)\n","4. [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n","5. [Stochastic Gradient Descent with momentum](https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d)"]},{"cell_type":"code","metadata":{"id":"b5n4RTu3wmfI"},"source":[""],"execution_count":null,"outputs":[]}]}