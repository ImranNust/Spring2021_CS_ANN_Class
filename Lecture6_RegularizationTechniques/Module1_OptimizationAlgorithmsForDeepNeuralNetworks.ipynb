{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Module1_OptimizationAlgorithmsForDeepNeuralNetworks.ipynb","provenance":[{"file_id":"1-FvUj5f6x00GJncw238nLzAF2Cckq9Hn","timestamp":1626162014105}],"collapsed_sections":[],"authorship_tag":"ABX9TyPCtD6ft9KoA/vRwXUhSXBS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3rtxEC-Rwrvv"},"source":["# Optimization Algorithms for Deep Neural Networks\n","\n","In this module, we will study:\n","1. Gradient Descent\n","2. Momentum-Based Gradient Descent\n","3. Nesterov Mementum\n","4. Adagrad\n","5. RMSProp\n","6. Adam\n"]},{"cell_type":"markdown","metadata":{"id":"zaGbgMHt16DS"},"source":["## Optimization Algorithms\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LwW3C2TH0p9h"},"source":["## References\n","\n","1. [A journey into Optimization algorithms for Deep Neural Networks](https://theaisummer.com/optimization/)\n","2. [The Hitchhikerâ€™s Guide to Optimization in Machine Learning](https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-machine-learning-edcf5a104210)\n","3. [Gradient Descent Explained](https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c)\n","4. [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)"]},{"cell_type":"code","metadata":{"id":"b5n4RTu3wmfI"},"source":[""],"execution_count":null,"outputs":[]}]}